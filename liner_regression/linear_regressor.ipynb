{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(X):\n",
    "    \"\"\"\n",
    "    This function transforms the 5 input features of matrix X (x_i denoting the i-th component of X) \n",
    "    into 21 new features phi(X) in the following manner:\n",
    "    5 linear features: phi_1(X) = x_1, phi_2(X) = x_2, phi_3(X) = x_3, phi_4(X) = x_4, phi_5(X) = x_5\n",
    "    5 quadratic features: phi_6(X) = x_1^2, phi_7(X) = x_2^2, phi_8(X) = x_3^2, phi_9(X) = x_4^2, phi_10(X) = x_5^2\n",
    "    5 exponential features: phi_11(X) = exp(x_1), phi_12(X) = exp(x_2), phi_13(X) = exp(x_3), phi_14(X) = exp(x_4), phi_15(X) = exp(x_5)\n",
    "    5 cosine features: phi_16(X) = cos(x_1), phi_17(X) = cos(x_2), phi_18(X) = cos(x_3), phi_19(X) = cos(x_4), phi_20(X) = cos(x_5)\n",
    "    1 constant features: phi_21(X)=1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: matrix of floats, dim = (700,5), inputs with 5 features\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_transformed: array of floats: dim = (700,21), transformed input with 21 features\n",
    "    \"\"\"\n",
    "    X_quad = np.square(X)\n",
    "    X_expo = np.exp(X)\n",
    "    X_cos = np.cos(X)\n",
    "    X_const = np.ones((np.shape(X)[0],1))\n",
    "    X_transformed = np.hstack([X, X_quad, X_expo, X_cos, X_const])\n",
    "    assert X_transformed.shape == (np.shape(X)[0], 21)\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, lam):\n",
    "    \"\"\"\n",
    "    This function receives training data points, transform them, and then fits the linear regression on this \n",
    "    transformed data. Finally, it outputs the weights of the fitted linear regression. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: matrix of floats, dim = (700,5), inputs with 5 features\n",
    "    y: array of floats, dim = (700,), input labels)\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    w: array of floats: dim = (21,), optimal parameters of linear regression\n",
    "    \"\"\"\n",
    "    w = np.zeros((21,))\n",
    "    X_transformed = transform_data(X)\n",
    "\n",
    "    reg = linear_model.Ridge(alpha=lam, fit_intercept=False)\n",
    "    reg.fit(X_transformed,y)\n",
    "    w = reg.coef_\n",
    "\n",
    "    assert w.shape == (21,)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_RMSE(w, X, y):\n",
    "    \"\"\"This function takes test data points (X and y), and computes the empirical RMSE of \n",
    "    predicting y from X using a linear model with weights w. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w: array of floats: dim = (13,), optimal parameters of ridge regression \n",
    "    X: matrix of floats, dim = (15,13), inputs with 13 features\n",
    "    y: array of floats, dim = (15,), input labels\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    RMSE: float: dim = 1, RMSE value\n",
    "    \"\"\"\n",
    "    RMSE = 0\n",
    "    y_pred = X.dot(w)\n",
    "    MSE = mean_squared_error(y, y_pred)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "\n",
    "    assert np.isscalar(RMSE)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_LR_RMSE(X, y, lambdas, n_folds):\n",
    "    \"\"\"\n",
    "    Main cross-validation loop, implementing 10-fold CV. In every iteration (for every train-test split), the RMSE for every lambda is calculated, \n",
    "    and then averaged over iterations.\n",
    "    \n",
    "    Parameters\n",
    "    ---------- \n",
    "    X: matrix of floats, dim = (150, 13), inputs with 13 features\n",
    "    y: array of floats, dim = (150, ), input labels\n",
    "    lambdas: list of floats, len = 5, values of lambda for which ridge regression is fitted and RMSE estimated\n",
    "    n_folds: int, number of folds (pieces in which we split the dataset), parameter K in KFold CV\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    avg_RMSE: array of floats: dim = (5,), average RMSE value for every lambda\n",
    "    \"\"\"\n",
    "    RMSE_mat = np.zeros((n_folds, len(lambdas)))\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    lambda_i = 0\n",
    "    for i, (train, test) in enumerate(kf.split(X)):\n",
    "        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "        for ii, l in enumerate(lambdas):\n",
    "            w = fit(X_train, y_train, l)\n",
    "            RMSE_mat[i][ii] = calculate_RMSE(w, transform_data(X_test), y_test)\n",
    "\n",
    "    avg_RMSE = np.mean(RMSE_mat, axis=0)\n",
    "    #assert avg_RMSE.shape == (1000,)\n",
    "    return avg_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x1    x2    x3    x4    x5\n",
      "0  0.02  0.05 -0.09 -0.43 -0.08\n",
      "1 -0.13  0.11 -0.08 -0.29 -0.03\n",
      "2  0.08  0.06 -0.07 -0.41 -0.03\n",
      "3  0.02 -0.12  0.01 -0.43 -0.02\n",
      "4 -0.14 -0.12 -0.08 -0.02 -0.08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data loading\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "y = data[\"y\"].to_numpy()\n",
    "data = data.drop(columns=[\"Id\", \"y\"])\n",
    "# print a few data samples\n",
    "print(data.head())\n",
    "X = data.to_numpy()\n",
    "\n",
    "#K fold hyperparameter search\n",
    "lambdas = [0.1, 1, 10, 100, 200]\n",
    "lambdas_2 = [x*0.1 for x in range(10,1011)]\n",
    "n_folds = 10\n",
    "avg_RMSE = average_LR_RMSE(X, y, lambdas_2, n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.800000000000004"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choosing best lam value\n",
    "best_lam = lambdas_2[np.argmin(avg_RMSE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x1    x2    x3    x4    x5\n",
      "0  0.02  0.05 -0.09 -0.43 -0.08\n",
      "1 -0.13  0.11 -0.08 -0.29 -0.03\n",
      "2  0.08  0.06 -0.07 -0.41 -0.03\n",
      "3  0.02 -0.12  0.01 -0.43 -0.02\n",
      "4 -0.14 -0.12 -0.08 -0.02 -0.08\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "y = data[\"y\"].to_numpy()\n",
    "data = data.drop(columns=[\"Id\", \"y\"])\n",
    "# print a few data samples\n",
    "print(data.head())\n",
    "\n",
    "X = data.to_numpy()\n",
    "\n",
    "w = fit(X, y, lam = best_lam)\n",
    "# Save results in the required format\n",
    "np.savetxt(\"./results_final_2.csv\", w, fmt=\"%.12f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iaf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
